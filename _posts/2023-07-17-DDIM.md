---
layout: single
title: "[Paper Review] DDIM(Denoising Diffusion Implicit Models)"
categories: Diffusion
tag: [Diffusion]
toc: true
author_profile: false
Typora-root-url: ../
use_math: true

---

# DDIM 

* Paper: Denoising Diffusion Implicit Models ; [arxiv](https://arxiv.org/abs/2010.02502)	

## Introduction

기존 DDPM에서는 reverse step을 설계했다기 보다는 forward process에서 어떤 식으로 noise를 주입할지 먼저 정한 후 forward process의 식으로 부터 denoising step을 bayes rule을 통해 유도하여서 이용하였다. Markov chain 특성을 사용해서 Forward, Reverse process를 모두 설계하였는데 이로 인해 Sampling시 모든 time step T를 거쳐서 원본이미지를 inference해야 하기에 시간이 너무 오래 걸리는 단점이 있다. 실제 DDIM논문에서도 이에 대해 언급하였다.

![DDPM_drawback](/images/2023-07-17-DDIM/DDPM_drawback.png)

이번 논문에서는 기존 DDPM의 학습 방법은 그대로 가져가면서 markov chain 특성을 끊고 non-markov chain 특성을 이용해 더 빠르게 sampling 하면서 동시에 좋은 quality를 가져가는 방법에 대해서 제시한다.

## BackGround

DDPM에서 제시했던 식들에 대해 알아보는 과정이다. <br/>Denoising Network p에 대한 marginal, joint distribution을 나타내면 다음과같다.

![Denoising process](/images/2023-07-17-DDIM/Denoising process.png)

$q(x_0)$를 알고 있을 때, denoising network p는 $p_{\theta}(x_0)$는 $q(x_0)$를 모사하기 위해 학습한다. 그리고 intractable한 $log(p_{\theta}(x_0))$를 해결하기 위해 ELBO를 이용하여 Objective Function을 도출했고 이는 다음과 같다.

$\underset{\theta}{max}&nbsp;&nbsp; \mathbb{E_{q(x_0)}}[p_{\theta}(x_0)] \le \underset{\theta}{max}&nbsp; \mathbb{E_{q(x_0), q_(x_1), \dots, q_(x_T) }}[log(p_{\theta}(x_{0:T})) - log(q(x_{1:T}\|x_0))]$

noise를 더하는 과정인 forward process는 markov chain성질에 의해 이루어지고 trainable하지 않고 fixed된 과정이다. 미리 scheduling 되어 있는 $\alpha_{1:T} \in (0,1]^T$에 의해 forward process는 다음과 같이 나타낼 수 있다.

![DDPM_forward](/images/2023-07-17-DDIM/DDPM_forward.png)

위 식을 reparemeterization trick을 이용해 나타내고 $x_{t-1}, x_{t-2}, \dots, x_0$에 대해 점진적으로 나타내면 $x_t$는 다음과 같이 정리된다.

$x_t = \sqrt{\bar\alpha_{t}}x_0 + \sqrt{1-\bar\alpha_{t}}\epsilon$ ($\bar\alpha_{t} = \prod_{i=1}^{T}\alpha_i$), where $\epsilon \sim \mathcal{N}(0,\mathcal{I})$

그리고 Loss function은 다음과 같이 나타낸다.

![General_Loss](/images/2023-07-17-DDIM/General_Loss.png)

$\gamma_t$의 값이 1일 때 training model에 대한 generation performance가 최대가 된다고 하여서 $\gamma_t$의 값은 1로 설정하였다.

## Variational Inference For Non-Markovian Forward Process

![non-markovian forward](/images/2023-07-17-DDIM/non-markovian forward.png)

Generative Process는 inference process의 역과정으로 이루어진다. 생성 속도를 향상 시키기 위해서는 iteration을 줄여야 하기에 이를 위한 inference process를 다시 생각해봐야 한다. DDPM에서 Loss식을 보면 marginal distribution $q(x_{T}\|x_0)$에만 의존하고, joint distribution인 $q(x_{1:T}\|x_0)$에는 의존하지 않는다. 같은 marginal distribution을 가지는 수많은 joint distribution(inference process)가 존재하기에 새로운 inference process를 탐구해볼 수 있다.

$q_{\sigma}(x_{1:T}\|x_0) := q_{\sigma}(x_T\|x_0) \prod_{t=2}^{T} q_{\sigma}(x_{t-1}\|x_t,x_0)$ 

<details>
<summary>증명)</summary>
$\prod_{t=1}^{T} q_{\sigma}(x_t|x_{t-1},x_0) = q_{\sigma}(x_1|x_0) \times q_{\sigma}(x_2|x_1,x_0) \times \dots \times q_{\sigma}(x_T|x_{T-1},x_0)$ 
$q_{\sigma}(x_t|x_{t-1},x_0) = \frac{q_{\sigma}(x_{t-1}|x_t,x_0) q_{\sigma}(x_t|x_0)}{q_{\sigma}(x_{t-1}|x_0)}$이기에<br/>

$\prod_{t=1}^{T} q_{\sigma}(x_t|x_{t-1},x_0) = q_{\sigma}(x_1|x_0) \times \frac{q_{\sigma}(x_{1}|x_2,x_0) q_{\sigma}(x_2|x_0)}{q_{\sigma}(x_{1}|x_0)} \times \frac{q_{\sigma}(x_{2}|x_3,x_0) q_{\sigma}(x_3|x_0)}{q_{\sigma}(x_{2}|x_0)} \times \dots \times \frac{q_{\sigma}(x_{T-1}|x_T,x_0) q_{\sigma}(x_T|x_0)}{q_{\sigma}(x_{T-1}|x_0)}$<br/>

 &ensp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;$= q_{\sigma}(x_T|x_0) \prod_{t=2}^{T} q_{\sigma}(x_{t-1}|x_t,x_0)$

</details><br/>





